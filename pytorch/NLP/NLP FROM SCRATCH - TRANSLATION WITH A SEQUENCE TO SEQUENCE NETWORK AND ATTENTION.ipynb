{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "        self.word2index = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        \n",
    "        self.word2count = {}\n",
    "\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "            \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "\n",
    "            self.word2count[word] = 1\n",
    "            \n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def unicode_2_ascii(unicode_string):\n",
    "    ascii_string = ''\n",
    "    \n",
    "    for char in unicodedata.normalize(\"NFD\", unicode_string):\n",
    "        if unicodedata.category(char) != \"Mn\":\n",
    "            ascii_string += char\n",
    "            \n",
    "    return ascii_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_string(string):\n",
    "    # Lowercase.\n",
    "    string = unicode_2_ascii(string.lower())\n",
    "    # Adds a space btw a letter and a [.!?].\n",
    "    string = re.sub(r\"([.!?])\", r\" \\1\", string)\n",
    "    # Removes non-letter chrs.\n",
    "    string = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Reads the file and split into lines.\n",
    "    with open(f\"data/{lang1}-{lang2}.txt\", encoding=\"utf-8\") as f:\n",
    "        lines = f.read().strip().split('\\n')\n",
    "        \n",
    "    # Splits every line into pairs and normalizes.\n",
    "    pairs = [[normalize_string(sentence.strip()) for sentence in line.split(\"\\t\")]\n",
    "                for line in lines]\n",
    "    \n",
    "    # Reverses pairs, makes Lang instances.\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        \n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filter_pair(pair):\n",
    "    return len(pair[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(pair[1].split(' ')) < MAX_LENGTH and \\\n",
    "        pair[1].startswith(eng_prefixes)\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['je suis heureuse que vous l ayez aime .', 'i m happy you liked it .']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def prepare_data(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1, lang2, reverse)\n",
    "    print(f\"Read {len(pairs)} sentence pairs\")\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n",
    "\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data(\"eng\", \"fra\", True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = self.hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, self.embed_size)\n",
    "        \n",
    "        self.gru = nn.GRU(self.embed_size, self.hidden_size)\n",
    "        \n",
    "    def forward(self, input_, hidden):\n",
    "#         output = embedding(input)\n",
    "#         input: (*), LongTensor of arbitrary shape containing the indices to extract\n",
    "#         output: (*, H), where * is the input shape and H=\\text{embedding\\_dim}H=embedding_dim\n",
    "        embedded = self.embedding(input_).view(1, 1, -1)\n",
    "        \n",
    "#         output, h_n = gru(input, h_0)\n",
    "#         input of shape (seq_len, batch, input_size)\n",
    "#         h_0 of shape (num_layers * num_directions, batch, hidden_size)\n",
    "#         output of shape (seq_len, batch, num_directions * hidden_size)\n",
    "#         h_n of shape (num_layers * num_directions, batch, hidden_size)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = self.hidden_size\n",
    "        \n",
    "        # Like a linear?\n",
    "        self.embedding = nn.Embedding(output_size, self.embed_size)\n",
    "        \n",
    "        self.gru = nn.GRU(self.embed_size, self.hidden_size)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_, hidden):\n",
    "        output = self.embedding(input_).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        output = self.out(output[0])\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hiddden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closer to a lesser-used \"location-based\" strategy from Luong et al\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)  # a list.\n",
    "    \n",
    "    # torch.tensor(indexes, dtype=torch.long, device=device) is a 1d tensor\n",
    "\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).unsqueeze_(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensors_from_pair(pair):\n",
    "    input_tensor = tensor_from_sentence(input_lang, pair[0])\n",
    "    target_tensor = tensor_from_sentence(output_lang, pair[1])\n",
    "    \n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, criterion, \n",
    "              encoder_optimizer, decoder_optimizer, max_length=MAX_LENGTH):\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # Encoder.\n",
    "    \n",
    "    # max_length of the sentence is max_length, \n",
    "    # each word in the sentence is repr by a vec.\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    # Encoder hidden.\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    \n",
    "    # Clears grads.\n",
    "    encoder_optimizer.zero_grad()\n",
    "\n",
    "    for e_idx in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[e_idx], encoder_hidden)\n",
    "\n",
    "        #         print(encoder_output.size()) is [1, 1, embed_size]\n",
    "        \n",
    "        encoder_outputs[e_idx] = encoder_output[0][0]\n",
    "\n",
    "    # Decoder.\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token], device=device)\n",
    "\n",
    "    # Decoder hidden.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # Clears grads.\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for d_idx in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[d_idx])\n",
    "            \n",
    "            decoder_input = target_tensor[d_idx]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        for d_idx in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "#             decoder_output.size() is [1, lang2.n_words]\n",
    "#             decoder_output.topk(k) -> [1, k], [1, k]\n",
    "            \n",
    "            top_values, top_indexes = decoder_output.topk(1)\n",
    "            \n",
    "#             top_indexes.size() is [1, 1]\n",
    "#             top_indexes.squeeze() removes '1' in top_indexes.size()\n",
    "            \n",
    "            decoder_input = top_indexes.squeeze().detach()  # detach from history as input\n",
    "        \n",
    "            loss += criterion(decoder_output, target_tensor[d_idx])\n",
    "            \n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    # Backward.\n",
    "    loss.backward()\n",
    "\n",
    "    # Upgrads params.\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def as_minutes(total_secs):\n",
    "    minutes = int(total_secs / 60)\n",
    "    seconds = total_secs - minutes * 60\n",
    "    \n",
    "    return f\"{minutes:.0f}m {seconds:.0f}s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    \n",
    "    total_secs = now - since\n",
    "    entire_secs = total_secs / percent\n",
    "    remaining_secs = entire_secs - total_secs\n",
    "    \n",
    "    return f\"{as_minutes(total_secs)} (- {as_minutes(remaining_secs)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_iters(encoder, decoder, n_iters, learning_rate=0.01, print_every=1000, plot_every=100):\n",
    "    # Init of vars for tracking the training process.\n",
    "    start = time.time()\n",
    "    \n",
    "    print_loss_total = 0\n",
    "    plot_losses = []\n",
    "    plot_loss_total = 0\n",
    "\n",
    "    # Loss func.\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Optimizers.\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_pairs = [tensors_from_pair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        # Gets a training example.\n",
    "        input_tensor, target_tensor = training_pairs[iter - 1]\n",
    "\n",
    "        #         print(input_tensor)\n",
    "        #         print(target_tensor)\n",
    "#         tensor([[351],\n",
    "#         [349],\n",
    "#         [376],\n",
    "#         [  5],\n",
    "#         [  1]], device='cuda:0')\n",
    "#         tensor([[221],\n",
    "#         [ 78],\n",
    "#         [ 72],\n",
    "#         [  4],\n",
    "#         [  1]], device='cuda:0')\n",
    "        \n",
    "        # Training.\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, criterion, encoder_optimizer, decoder_optimizer)\n",
    "\n",
    "        # Tracks the training process.\n",
    "        print_loss_total += loss\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            percent = iter / n_iters\n",
    "            print(f\"{time_since(start, percent)} ({iter} {percent:.0%}) {print_loss_avg:.4f}\")\n",
    "            print_loss_total = 0\n",
    "        \n",
    "        plot_loss_total += loss\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def show_plot(losses):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    \n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Encoder. \n",
    "        \n",
    "        input_tensor = tensor_from_sentence(input_lang, sentence)\n",
    "        \n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "                \n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "        for e_idx in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[e_idx],\n",
    "                                                     encoder_hidden)\n",
    "            \n",
    "            encoder_outputs[e_idx] += encoder_output[0, 0]\n",
    "\n",
    "        # Decoder.\n",
    "        \n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for d_idx in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            decoder_attentions[d_idx] = decoder_attention.data\n",
    "            \n",
    "            top_values, top_idxs = decoder_output.data.topk(1)\n",
    "            \n",
    "            decoder_input = top_idxs.squeeze().detach()\n",
    "            \n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[top_idxs.item()])\n",
    "\n",
    "        return decoded_words, decoder_attentions[:d_idx + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 16s (- 31m 50s) (5000 7%) 2.8381\n",
      "4m 29s (- 29m 11s) (10000 13%) 2.2792\n",
      "6m 44s (- 26m 57s) (15000 20%) 1.9879\n",
      "8m 59s (- 24m 42s) (20000 27%) 1.7277\n",
      "11m 16s (- 22m 31s) (25000 33%) 1.5311\n"
     ]
    }
   ],
   "source": [
    "# Training.\n",
    "train_iters(encoder, attn_decoder, n_iters=75_000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating.\n",
    "evaluate_randomly(encoder, attn_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Shows the colored matrix.\n",
    "    color_ax = ax.matshow(attentions)\n",
    "    \n",
    "    # Shows a color bar.\n",
    "    fig.colorbar(color_ax)\n",
    "    \n",
    "    # Sets up axes.\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels(['' + output_words])\n",
    "    \n",
    "    # Shows labels at every tick.\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_show_attention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, attn_decoder, input_sentence)\n",
    "    \n",
    "    print(\"input =\", input_sentence)\n",
    "    print(\"output =\", ' '.join(output_words))\n",
    "    \n",
    "    show_attention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
