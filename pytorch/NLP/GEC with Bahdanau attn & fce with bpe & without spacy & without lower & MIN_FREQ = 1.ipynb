{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import TranslationDataset\n",
    "\n",
    "class GEC_DATASET(TranslationDataset):\n",
    "    @classmethod\n",
    "    def splits(cls, \n",
    "               exts, \n",
    "               fields, \n",
    "               root, \n",
    "               train=\"train\", \n",
    "               validation=\"dev\", \n",
    "               test=\"test\", \n",
    "               **kwargs):\n",
    "        \n",
    "        return super(GEC_DATASET, cls).splits(exts=exts, \n",
    "                                      fields=fields,\n",
    "                                      path=root, \n",
    "                                      root=root,\n",
    "                                      train=train, \n",
    "                                      validation=validation, \n",
    "                                      test=test,\n",
    "                                      **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "def prepare_data(root):\n",
    "    src_field = Field(init_token=\"<sos>\", eos_token=\"<eos>\", tokenize=lambda sentence: sentence.split(' '))\n",
    "    trg_field = Field(init_token=\"<sos>\", eos_token=\"<eos>\", tokenize=lambda sentence: sentence.split(' '))\n",
    "    \n",
    "    #? Should be lower?\n",
    "    \n",
    "    train_set, valid_set, test_set = GEC_DATASET.splits(exts=('.src', '.trg'), \n",
    "                                                        fields=(src_field, trg_field),\n",
    "                                                        root=root,\n",
    "                                                        filter_pred=lambda sentence: \n",
    "                                                        len(vars(sentence)['src']) < MAX_LEN \n",
    "                                                        and len(vars(sentence)['trg']) < MAX_LEN)\n",
    "\n",
    "    src_field.build_vocab(train_set, min_freq=MIN_FREQ)\n",
    "    trg_field.build_vocab(train_set, min_freq=MIN_FREQ)\n",
    "\n",
    "    train_iter, valid_iter, test_iter = BucketIterator.splits(\n",
    "        datasets=(train_set, valid_set, test_set), \n",
    "        batch_size=BATCH_SIZE,\n",
    "        device=DEVICE)\n",
    "    \n",
    "    return src_field, trg_field, train_iter, valid_iter, test_iter, train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size):  \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(src_vocab_size, ENC_EMB_DIM)\n",
    "        self.dropout = nn.Dropout(ENC_DROPOUT)  #+ dropout\n",
    "        \n",
    "        self.gru = nn.GRU(ENC_EMB_DIM, ENC_HID_DIM, bidirectional=True)\n",
    "        \n",
    "        self.fc = nn.Linear(ENC_HID_DIM * 2, DEC_HID_DIM)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # (in)  inputs: [src_len, batch_size]\n",
    "        # (out) outputs: [src_len, batch_size, enc_hid_dim * 2]\n",
    "        # (out) hidden: [batch_size, dec_hid_dim]\n",
    "        \n",
    "        # (in)  inputs\n",
    "        # (out) embedded: [src_len, batch_size, enc_emb_dim]\n",
    "        embedded = self.dropout(\n",
    "            self.embedding(inputs))\n",
    "        \n",
    "        # (in)  embedded\n",
    "        # (out) outputs: [src_len, batch_size, enc_hid_dim * 2]\n",
    "        # (out) hiddens: [2, batch_size, enc_hid_dim]\n",
    "        outputs, hiddens = self.gru(embedded)\n",
    "        \n",
    "        # (in)  hiddens\n",
    "        # (out) hidden: [batch_size, dec_hid_dim]\n",
    "        hidden = torch.tanh(\n",
    "            self.fc(\n",
    "                torch.cat((hiddens[0], \n",
    "                           hiddens[1]), dim=1)))\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(DEC_HID_DIM + ENC_HID_DIM * 2, ATTN_V_DIM)\n",
    "        self.v = nn.Parameter(torch.rand(1, ATTN_V_DIM))\n",
    "        \n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        # (in)  decoder_hidden: [batch_size, dec_hid_dim]\n",
    "        # (in)  encoder_outputs: [src_len, batch_size, enc_hid_dim * 2]\n",
    "        # (out) attn: [batch_size, src_len]\n",
    "        \n",
    "        # (in)  decoder_hidden\n",
    "        # (in)  encoder_outputs\n",
    "        # (out) energy: [batch_size, src_len, attn_v_dim]\n",
    "        energy = torch.tanh(\n",
    "            self.fc(\n",
    "                torch.cat((\n",
    "                    decoder_hidden.unsqueeze(1).repeat(1, encoder_outputs.size()[0], 1), \n",
    "                    encoder_outputs.permute(1, 0, 2)), dim=2)))\n",
    "        \n",
    "        # (in)  v: [1, attn_v_dim]\n",
    "        # (in)  energy\n",
    "        # (out) attn: [batch_size, src_len]\n",
    "        attn = F.softmax(self.v.unsqueeze(0).repeat(energy.size()[0], 1, 1).bmm(energy.permute(0, 2, 1)), dim=2).squeeze(1)  #m\n",
    "        \n",
    "        return attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, trg_vocab_size):  \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(trg_vocab_size, DEC_EMB_DIM)\n",
    "        self.dropout = nn.Dropout(DEC_DROPOUT)  #+ dropout\n",
    "        \n",
    "        self.attn = Attn()\n",
    "        \n",
    "        self.gru = nn.GRU(DEC_EMB_DIM + ENC_HID_DIM * 2, DEC_HID_DIM)\n",
    "        \n",
    "        self.fc = nn.Linear(DEC_EMB_DIM + ENC_HID_DIM * 2 + DEC_HID_DIM, trg_vocab_size)\n",
    "        \n",
    "    def forward(self, last_output, decoder_hidden, encoder_outputs):\n",
    "        # (in)  last_output: [batch_size]\n",
    "        # (in)  decoder_hidden: [batch_size, dec_hid_dim]\n",
    "        # (in)  encoder_outputs: [src_len, batch_size, enc_hid_dim * 2]\n",
    "        #!(out) decoder_outputs: [batch_size, trg_vocab_size]\n",
    "        # (out) decoder_hidden: [batch_size, dec_hid_dim]\n",
    "        \n",
    "        # (in)  last_output\n",
    "        # (out) embedded: [batch_size, dec_emb_dim]\n",
    "        embedded = self.dropout(\n",
    "            self.embedding(last_output))\n",
    "        \n",
    "        # (in)  decoder_hidden\n",
    "        # (in)  encoder_outputs\n",
    "        # (out) attn: [batch_size, src_len]\n",
    "        attn = self.attn(decoder_hidden, encoder_outputs)\n",
    "        # (in)  attn\n",
    "        # (in)  encoder_outputs\n",
    "        # (out) context: [batch, enc_hid_dim * 2]\n",
    "        context = attn.unsqueeze(1).bmm(encoder_outputs.permute(1, 0, 2)).squeeze(1)\n",
    "\n",
    "        # (in)  embedded\n",
    "        # (in)  context\n",
    "        # (in)  decoder_hidden\n",
    "        # (out) outputs: [1, batch_size, dec_hid_dim]\n",
    "        # (out) decoder_hidden: [1, batch_size, dec_hid_dim]\n",
    "        outputs, decoder_hidden = self.gru(\n",
    "            torch.cat((embedded.unsqueeze(0), \n",
    "                       context.unsqueeze(0)), dim=2), \n",
    "            decoder_hidden.unsqueeze(0))\n",
    "        \n",
    "        # (in)  embedded\n",
    "        # (in)  context\n",
    "        # (in)  decoder_hidden\n",
    "        # (out) decoder_outputs: [batch_size, trg_vocab_size]\n",
    "        decoder_outputs = self.fc(\n",
    "            torch.cat((embedded, \n",
    "                       context, \n",
    "                       decoder_hidden.squeeze(0)), dim=1))\n",
    "        \n",
    "        return decoder_outputs, decoder_hidden.squeeze(0), attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(src_vocab_size)\n",
    "        self.decoder = Decoder(trg_vocab_size)\n",
    "        \n",
    "        self.trg_vocab_size = trg_vocab_size\n",
    "        \n",
    "    def forward(self, inputs, trgs, teacher_forcing_ratio=0.5):\n",
    "        # (in)  inputs: [src_len, batch_size]\n",
    "        # (in)  trgs: [trg_len, batch_size]\n",
    "        # (out) outputs: [trg_len, batch_size, trg_vocab_size]\n",
    "        \n",
    "        # seq len of inputs and trgs may not always be the same\n",
    "                \n",
    "        # Encode.\n",
    "        # (in)  inputs\n",
    "        # (out) encoder_outputs: [src_len, batch_size, enc_hid_dim * 2]\n",
    "        # (out) decoder_hidden: [batch_size, dec_hid_dim]\n",
    "        encoder_outputs, decoder_hidden = self.encoder(inputs)\n",
    "        \n",
    "        # Decode.\n",
    "        trg_len = trgs.size()[0]\n",
    "        batch_size = trgs.size()[1]\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, self.trg_vocab_size, device=DEVICE)\n",
    "\n",
    "        decoder_outputs = trgs[0]\n",
    "        for t in range(1, trg_len):\n",
    "            # (in)  decoder_output: [batch_size]\n",
    "            # (in)  decoder_hidden\n",
    "            # (in)  encoder_outputs\n",
    "            #!(out) decoder_outputs: [batch_size, trg_vocab_size]\n",
    "            # (out) decoder_hidden: [batch_size, dec_hid_dim]\n",
    "            decoder_outputs, decoder_hidden, _ = self.decoder(decoder_outputs, \n",
    "                                                           decoder_hidden, \n",
    "                                                           encoder_outputs)\n",
    "            \n",
    "            outputs[t] = decoder_outputs\n",
    "            \n",
    "            decoder_outputs = decoder_outputs.argmax(dim=1) if teacher_forcing_ratio <= random.random() else trgs[t]\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):  #+ init weights\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train(train_iter, model, criterion, optimizer):\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_iter:\n",
    "        \n",
    "        # Gets data.\n",
    "        srcs = batch.src\n",
    "        trgs = batch.trg\n",
    "        \n",
    "        # Forward.\n",
    "        outputs = model(srcs, trgs)\n",
    "        \n",
    "        # Loss.\n",
    "        loss = criterion(outputs[1:].view(-1, outputs.size()[-1]), \n",
    "                         trgs[1:].view(-1))  #m\n",
    "        \n",
    "        # Backward.\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)  #+\n",
    "        \n",
    "        # Updates params\n",
    "        optimizer.step()\n",
    "        # Zeros grad.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    return train_loss / len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate(data_iter, model, criterion):\n",
    "    \n",
    "    eval_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_iter:\n",
    "\n",
    "            # Gets data.\n",
    "            srcs = batch.src\n",
    "            trgs = batch.trg\n",
    "\n",
    "            # Forward.\n",
    "            outputs = model(srcs, trgs, 0)\n",
    "\n",
    "            # Loss.\n",
    "            loss = criterion(outputs[1:].view(-1, outputs.size()[-1]), \n",
    "                             trgs[1:].view(-1))  #m\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "        \n",
    "        return eval_loss / len(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_track(start, end):\n",
    "    \n",
    "    elapsed_time = end - start\n",
    "    \n",
    "    mins = int(elapsed_time / 60)\n",
    "    secs = int(elapsed_time % 60)\n",
    "    \n",
    "    return f\"{mins:>2}mins {secs:>2}secs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import copy\n",
    "\n",
    "def train(train_iter, valid_iter, model, criterion, optimizer):\n",
    "        \n",
    "    min_valid_loss = float(\"inf\")  #+\n",
    "    \n",
    "    for epoch in range(N_EPOCHS):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        train_loss = _train(train_iter, model, criterion, optimizer)\n",
    "        valid_loss = _evaluate(valid_iter, model, criterion)\n",
    "    \n",
    "        end = time.time()\n",
    "        \n",
    "        print(f\"epoch: {epoch + 1:02}, time: {time_track(start, end)}\")\n",
    "        print(f\"train loss: {train_loss:.3f}, train ppl: {math.exp(train_loss):.3f}\")\n",
    "        print(f\"valid loss: {valid_loss:.3f}, valid ppl: {math.exp(valid_loss):.3f}\")\n",
    "        \n",
    "        if valid_loss < min_valid_loss:  #+\n",
    "            min_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), PT)\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_iter, model, criterion):\n",
    "    model.load_state_dict(torch.load(PT))\n",
    "    \n",
    "    test_loss = _evaluate(test_iter, model, criterion)\n",
    "\n",
    "    print(f\"test loss: {test_loss:.3f}, test ppl: {math.exp(test_loss):.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference  #+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sentence(sentence, src_field, trg_field, model):\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [token for token in sentence.split(' ')]\n",
    "    else:\n",
    "        tokens = sentence\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.tensor(src_indexes, dtype=torch.long, device=DEVICE).unsqueeze(1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "    attentions = torch.zeros(MAX_LEN, 1, len(src_indexes), device=DEVICE)\n",
    "    \n",
    "    for i in range(MAX_LEN):\n",
    "\n",
    "        trg_tensor = torch.tensor([trg_indexes[-1]], dtype=torch.long, device=DEVICE)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
    "            \n",
    "        pred_token = output.argmax(1).item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "        attentions[i] = attention\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(sentence, correction, attention):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def inference(dataset, src_field, trg_field, model):\n",
    "    \n",
    "    for _ in range(10):\n",
    "        example_idx = random.randint(1, len(dataset))\n",
    "        \n",
    "        src = vars(dataset.examples[example_idx])['src']\n",
    "        trg = vars(dataset.examples[example_idx])['trg']\n",
    "\n",
    "        print(f\"src = {' '.join(src)}\")\n",
    "        print(f\"trg = {' '.join(trg)}\")\n",
    "        \n",
    "        correction, attention = correct_sentence(src, src_field, trg_field, model)\n",
    "        \n",
    "        print(f\"out = {' '.join(correction[:-1])}\")\n",
    "        \n",
    "        print('---')\n",
    "        \n",
    "#         display_attention(src, correction, attention)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU #+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def calculate_bleu(data, src_field, trg_field, model):\n",
    "    \n",
    "    trgs = []\n",
    "    outs = []\n",
    "    \n",
    "    for datum in data:\n",
    "        \n",
    "        src = vars(datum)['src']\n",
    "        trg = vars(datum)['trg']\n",
    "        \n",
    "        out, _ = correct_sentence(src, src_field, trg_field, model)\n",
    "        \n",
    "        #cut off <eos> token\n",
    "        out = out[:-1]\n",
    "        \n",
    "        outs.append(out)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    return bleu_score(outs, trgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 01, time:  4mins 20secs\n",
      "train loss: 5.119, train ppl: 167.152\n",
      "valid loss: 4.274, valid ppl: 71.784\n",
      "epoch: 02, time:  4mins 27secs\n",
      "train loss: 3.303, train ppl: 27.200\n",
      "valid loss: 3.059, valid ppl: 21.311\n",
      "epoch: 03, time:  4mins 26secs\n",
      "train loss: 2.178, train ppl: 8.830\n",
      "valid loss: 2.618, valid ppl: 13.707\n",
      "epoch: 04, time:  4mins 23secs\n",
      "train loss: 1.646, train ppl: 5.189\n",
      "valid loss: 2.464, valid ppl: 11.756\n",
      "epoch: 05, time:  4mins 24secs\n",
      "train loss: 1.323, train ppl: 3.754\n",
      "valid loss: 2.346, valid ppl: 10.443\n",
      "epoch: 06, time:  4mins 33secs\n",
      "train loss: 1.090, train ppl: 2.975\n",
      "valid loss: 2.287, valid ppl: 9.843\n",
      "epoch: 07, time:  4mins 24secs\n",
      "train loss: 0.919, train ppl: 2.506\n",
      "valid loss: 2.332, valid ppl: 10.299\n",
      "epoch: 08, time:  4mins 22secs\n",
      "train loss: 0.783, train ppl: 2.188\n",
      "valid loss: 2.327, valid ppl: 10.251\n",
      "epoch: 09, time:  4mins 25secs\n",
      "train loss: 0.679, train ppl: 1.973\n",
      "valid loss: 2.372, valid ppl: 10.717\n",
      "epoch: 10, time:  4mins 25secs\n",
      "train loss: 0.581, train ppl: 1.788\n",
      "valid loss: 2.436, valid ppl: 11.429\n",
      "\n",
      "test loss: 2.960, test ppl: 19.298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    DATASET = \"../data/fce with bpe\"\n",
    "    \n",
    "    # Prepares for data.\n",
    "    ROOT = f\"{DATASET}/parallel\"\n",
    "    MAX_LEN = 200\n",
    "    MIN_FREQ = 1\n",
    "    BATCH_SIZE = 16\n",
    "\n",
    "    src_field, trg_field, train_iter, valid_iter, test_iter, train_set, valid_set, test_set = prepare_data(root=ROOT)\n",
    "    \n",
    "    # Model.\n",
    "    ENC_EMB_DIM = 256\n",
    "    ENC_HID_DIM = 512\n",
    "    ENC_DROPOUT = 0.5\n",
    "    ENC_DROPOUT = 0\n",
    "\n",
    "    DEC_EMB_DIM = 256\n",
    "    DEC_HID_DIM = 512\n",
    "    DEC_DROPOUT = 0.5\n",
    "    DEC_DROPOUT = 0\n",
    "    \n",
    "    ATTN_V_DIM = DEC_HID_DIM  #m\n",
    "    \n",
    "    model = Seq2Seq(len(src_field.vocab), len(trg_field.vocab)).to(DEVICE)\n",
    "    model.apply(init_weights)\n",
    "    \n",
    "    # Criterion.\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=trg_field.vocab.stoi[\"<pad>\"])\n",
    "    \n",
    "    # Optimizer.\n",
    "    LR = 0.0003\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)  #n Decreasing lr makes the change of valid_loss slowlier, thus easier to get the optimal?\n",
    "    \n",
    "    # Trains and validates.\n",
    "    N_EPOCHS = 10\n",
    "    CLIP = 1  #+\n",
    "    PT = f\"{DATASET}.pt\"\n",
    "    \n",
    "    train(train_iter, valid_iter, model, criterion, optimizer)\n",
    "    \n",
    "    # Tests.\n",
    "    test(test_iter, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training inference\n",
      "src = It is a really great pleasure going in and out from different shops , try on a variety of clothes and shoes , and finally go back home with do@@ zens of bags in your hands .\n",
      "trg = It is a really great pleasure going in and out of different shops , trying on a variety of clothes and shoes , and finally going back home with do@@ zens of bags in your hands .\n",
      "out = It is a really great pleasure going in and out from different shops , try on a variety of clothes and shoes and finally finally back home with do@@ zens of bags in your hands .\n",
      "---\n",
      "src = Yours sincerely ,\n",
      "trg = Yours sincerely ,\n",
      "out = Yours sincerely ,\n",
      "---\n",
      "src = Teresa .\n",
      "trg = Teresa .\n",
      "out = Teresa .\n",
      "---\n",
      "src = In the 21st century , people will all the wearing the same clothes , the same shoes , they will be buying the same accessories .\n",
      "trg = In the 21st century , people will all the wearing the same clothes , the same shoes , they will be buying the same accessories .\n",
      "out = In the 21st century , people will all the wearing the same clothes , the same shoes , they will be buying the same environment .\n",
      "---\n",
      "src = With Love .\n",
      "trg = With Love .\n",
      "out = With Love .\n",
      "---\n",
      "src = Moreover , will come some teacher , of course all the students and the Principal .\n",
      "trg = Moreover , some teachers will come , of course all the students and the Principal .\n",
      "out = Moreover , will come some teacher , of course all the students and the Principal .\n",
      "---\n",
      "src = FOR ALL THIS REAS@@ ONS MY EVENING WAS TERRIBLE AND I WOULD LIKE TO RECEI@@ VE AT LEAST PART OF MY MONEY BACK .\n",
      "trg = FOR ALL THESE REAS@@ ONS MY EVENING WAS TERRIBLE AND I WOULD LIKE TO RECEI@@ VE AT LEAST PART OF MY MONEY BACK .\n",
      "out = FOR ALL THESE REAS@@ ONS MY EVENING WAS TERRIBLE AND I WOULD LIKE TO RECEI@@ VE AT LEAST PART OF MY MONEY BACK .\n",
      "---\n",
      "src = According to the advertisement , I could visit it after the show , but it was closed because of the lack of customers .\n",
      "trg = According to the advertisement , I could visit it after the show , but it was closed because of the lack of customers .\n",
      "out = According to the advertisement , I could visit it after the show , but it was closed because of the lack of customers .\n",
      "---\n",
      "src = I am writing to you because of the latest musical show you played in Circle Theatre .\n",
      "trg = I am writing to you because of the latest musical show you put on in the Circle Theatre .\n",
      "out = I am writing to you because of the the musical musical show you performed in the Circle Theatre .\n",
      "---\n",
      "src = Certainly it will be easier and faster than write , but it was nice when you were waiting for a letter .\n",
      "trg = Certainly this is easier and faster than writing , but it was nice when you were waiting for a letter .\n",
      "out = Certainly it will be easier and faster than write , but it was nice when you were waiting for a letter .\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"training inference\")\n",
    "inference(train_set, src_field, trg_field, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating inference\n",
      "src = Yours sincerely\n",
      "trg = Yours sincerely\n",
      "out = Yours sincerely\n",
      "---\n",
      "src = So , I hope I will get my money back , it was very disappointing evening out in my life ! I hope you understand me !\n",
      "trg = So , I hope I will get my money back . It was a very disappointing evening in my life ! I hope you understand me !\n",
      "out = So , I hope I will get my money back . It was very disappointing evening out out of my life ! I hope you understand me !\n",
      "---\n",
      "src = The question is : Do I need some extra money and what kind of clothes should I take for this trip ?\n",
      "trg = The question is : Do I need some extra money and what kind of clothes should I take for this trip ?\n",
      "out = The question is : I do I need some extra money and what kind of clothes should I take for this trip ?\n",
      "---\n",
      "src = Then , we can go to the show during that period\n",
      "trg = Then , we can go to the show during that period .\n",
      "out = Then , we can go to the show during that time ?\n",
      "---\n",
      "src = JUST BE Y@@ OUR@@ S@@ EL@@ F\n",
      "trg = JUST BE Y@@ OUR@@ S@@ EL@@ F\n",
      "out = DO MY Y@@ VI@@ S@@ EL@@ ON\n",
      "---\n",
      "src = I thought he was very rude , but I was wrong , he is n't arro@@ gant at all and he looks very simply .\n",
      "trg = I thought he was very rude , but I was wrong , he is n't arro@@ gant at all and he looks very simply .\n",
      "out = I thought he was very rude , but I was wrong , he is n't reduced at at all and he looked very very very . .\n",
      "---\n",
      "src = Well , it was the beginning of my trage@@ dy .\n",
      "trg = Well , that was the beginning of my trage@@ dy .\n",
      "out = Well , it was the beginning of my odd dy .\n",
      "---\n",
      "src = It had already closed , when the show finished .\n",
      "trg = It had already closed when the show finished .\n",
      "out = It had already closed when when the show finished .\n",
      "---\n",
      "src = All work I needed to do was n't very interesting . which I must have set thousands chairs correctly and after finishing I put them back nic@@ ely .\n",
      "trg = All the work I needed to do was n't very interesting . I must have set thousands of chairs correctly and after finishing I put them back nic@@ ely .\n",
      "out = All work I needed to do n't n't very interesting . I I have studied po@@ ag@@ ments and after I had to buy anything about .\n",
      "---\n",
      "src = I am looking forward to hearing from you .\n",
      "trg = I am looking forward to hearing from you .\n",
      "out = I am looking forward to hearing from you .\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"validating inference\")\n",
    "inference(valid_set, src_field, trg_field, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing inference\n",
      "src = In the past the people did n't have elec@@ tic@@ ity and if they wanted for example to read or to cook something they used to do in the fire .\n",
      "trg = In the past people did n't have electricity and if they wanted , for example , to read or to cook something they used to light a fire .\n",
      "out = In the past the people did n't have a e@@ and and they they wanted for example to read or to cook something they used to do in the fire .\n",
      "---\n",
      "src = The second one is the la@@ mp , the electricity that is very important in our life .\n",
      "trg = The second one is the la@@ mp , the electricity that is very important in our life .\n",
      "out = The second one is the la@@ circumstances , the is that is very important in our life .\n",
      "---\n",
      "src = I am writing to answer your question about the information on an interesting building to visit .\n",
      "trg = I am writing to answer your question about an interesting building to visit .\n",
      "out = I am writing to answer your question about the information on an interesting .\n",
      "---\n",
      "src = Dear Mrs Smith ,\n",
      "trg = Dear Mrs Smith ,\n",
      "out = Dear Mrs Smith ,\n",
      "---\n",
      "src = The Old T@@ own is the best place for afternoon stro@@ ll with a great deal of restaurants , ca@@ ff@@ es and street perform@@ ers .\n",
      "trg = The Old T@@ own is the best place for an afternoon stro@@ ll , with a great deal of restaurants , ca@@ f@@ es and street perform@@ ers .\n",
      "out = The band T@@ own is the best place for the capital to with a great deal of restaurants , ca@@ ff@@ es and street ay . .\n",
      "---\n",
      "src = I think I have to drive the car myself , so that it will know more about the advantages of using the car .\n",
      "trg = I think I have to drive the car myself , so that I will know more about the advantages of using a car .\n",
      "out = I think I have to carry the car myself , so that it will know more about the the of using the car .\n",
      "---\n",
      "src = Today , this kind of thing hardly happens !\n",
      "trg = Today , this kind of thing hardly ever happens !\n",
      "out = Today , this kind of thing it happened !\n",
      "---\n",
      "src = When you go out of the Hotel turn right and go st@@ right on , at the first cro@@ ss@@ roads turn right again .\n",
      "trg = When you go out of the hotel turn right and go straight on ; turn right again at the first cro@@ ss@@ roads .\n",
      "out = When you go out of the hotel sound right and and I used to the right , at the first hy@@ y@@ b@@ lan@@ right again .\n",
      "---\n",
      "src = It has been a plus for me .\n",
      "trg = It has been a plus for me .\n",
      "out = It has been a full for me .\n",
      "---\n",
      "src = Just take the bus 8@@ 3 or the sub - way .\n",
      "trg = Just take the 8@@ 3 bus or the sub@@ way .\n",
      "out = We take the bus place 3 or the cheapest - way .\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"testing inference\")\n",
    "inference(test_set, src_field, trg_field, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 52.12\n"
     ]
    }
   ],
   "source": [
    "bleu = calculate_bleu(test_set, src_field, trg_field, model)\n",
    "print(f'BLEU score = {bleu*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

