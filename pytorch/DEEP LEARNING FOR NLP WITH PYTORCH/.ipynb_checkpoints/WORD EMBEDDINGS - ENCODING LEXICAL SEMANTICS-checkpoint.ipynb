{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD EMBEDDINGS: ENCODING LEXICAL SEMANTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fab8a4158b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context size.\n",
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['When', 'forty'], 'winters')\n",
      "(['forty', 'winters'], 'shall')\n",
      "(['winters', 'shall'], 'besiege')\n",
      "(['shall', 'besiege'], 'thy')\n",
      "(['besiege', 'thy'], 'brow,')\n",
      "(['thy', 'brow,'], 'And')\n",
      "(['brow,', 'And'], 'dig')\n",
      "(['And', 'dig'], 'deep')\n",
      "(['dig', 'deep'], 'trenches')\n",
      "(['deep', 'trenches'], 'in')\n",
      "(['trenches', 'in'], 'thy')\n",
      "(['in', 'thy'], \"beauty's\")\n",
      "(['thy', \"beauty's\"], 'field,')\n",
      "([\"beauty's\", 'field,'], 'Thy')\n",
      "(['field,', 'Thy'], \"youth's\")\n",
      "(['Thy', \"youth's\"], 'proud')\n",
      "([\"youth's\", 'proud'], 'livery')\n",
      "(['proud', 'livery'], 'so')\n",
      "(['livery', 'so'], 'gazed')\n",
      "(['so', 'gazed'], 'on')\n",
      "(['gazed', 'on'], 'now,')\n",
      "(['on', 'now,'], 'Will')\n",
      "(['now,', 'Will'], 'be')\n",
      "(['Will', 'be'], 'a')\n",
      "(['be', 'a'], \"totter'd\")\n",
      "(['a', \"totter'd\"], 'weed')\n",
      "([\"totter'd\", 'weed'], 'of')\n",
      "(['weed', 'of'], 'small')\n",
      "(['of', 'small'], 'worth')\n",
      "(['small', 'worth'], 'held:')\n",
      "(['worth', 'held:'], 'Then')\n",
      "(['held:', 'Then'], 'being')\n",
      "(['Then', 'being'], 'asked,')\n",
      "(['being', 'asked,'], 'where')\n",
      "(['asked,', 'where'], 'all')\n",
      "(['where', 'all'], 'thy')\n",
      "(['all', 'thy'], 'beauty')\n",
      "(['thy', 'beauty'], 'lies,')\n",
      "(['beauty', 'lies,'], 'Where')\n",
      "(['lies,', 'Where'], 'all')\n",
      "(['Where', 'all'], 'the')\n",
      "(['all', 'the'], 'treasure')\n",
      "(['the', 'treasure'], 'of')\n",
      "(['treasure', 'of'], 'thy')\n",
      "(['of', 'thy'], 'lusty')\n",
      "(['thy', 'lusty'], 'days;')\n",
      "(['lusty', 'days;'], 'To')\n",
      "(['days;', 'To'], 'say,')\n",
      "(['To', 'say,'], 'within')\n",
      "(['say,', 'within'], 'thine')\n",
      "(['within', 'thine'], 'own')\n",
      "(['thine', 'own'], 'deep')\n",
      "(['own', 'deep'], 'sunken')\n",
      "(['deep', 'sunken'], 'eyes,')\n",
      "(['sunken', 'eyes,'], 'Were')\n",
      "(['eyes,', 'Were'], 'an')\n",
      "(['Were', 'an'], 'all-eating')\n",
      "(['an', 'all-eating'], 'shame,')\n",
      "(['all-eating', 'shame,'], 'and')\n",
      "(['shame,', 'and'], 'thriftless')\n",
      "(['and', 'thriftless'], 'praise.')\n",
      "(['thriftless', 'praise.'], 'How')\n",
      "(['praise.', 'How'], 'much')\n",
      "(['How', 'much'], 'more')\n",
      "(['much', 'more'], 'praise')\n",
      "(['more', 'praise'], \"deserv'd\")\n",
      "(['praise', \"deserv'd\"], 'thy')\n",
      "([\"deserv'd\", 'thy'], \"beauty's\")\n",
      "(['thy', \"beauty's\"], 'use,')\n",
      "([\"beauty's\", 'use,'], 'If')\n",
      "(['use,', 'If'], 'thou')\n",
      "(['If', 'thou'], 'couldst')\n",
      "(['thou', 'couldst'], 'answer')\n",
      "(['couldst', 'answer'], \"'This\")\n",
      "(['answer', \"'This\"], 'fair')\n",
      "([\"'This\", 'fair'], 'child')\n",
      "(['fair', 'child'], 'of')\n",
      "(['child', 'of'], 'mine')\n",
      "(['of', 'mine'], 'Shall')\n",
      "(['mine', 'Shall'], 'sum')\n",
      "(['Shall', 'sum'], 'my')\n",
      "(['sum', 'my'], 'count,')\n",
      "(['my', 'count,'], 'and')\n",
      "(['count,', 'and'], 'make')\n",
      "(['and', 'make'], 'my')\n",
      "(['make', 'my'], 'old')\n",
      "(['my', 'old'], \"excuse,'\")\n",
      "(['old', \"excuse,'\"], 'Proving')\n",
      "([\"excuse,'\", 'Proving'], 'his')\n",
      "(['Proving', 'his'], 'beauty')\n",
      "(['his', 'beauty'], 'by')\n",
      "(['beauty', 'by'], 'succession')\n",
      "(['by', 'succession'], 'thine!')\n",
      "(['succession', 'thine!'], 'This')\n",
      "(['thine!', 'This'], 'were')\n",
      "(['This', 'were'], 'to')\n",
      "(['were', 'to'], 'be')\n",
      "(['to', 'be'], 'new')\n",
      "(['be', 'new'], 'made')\n",
      "(['new', 'made'], 'when')\n",
      "(['made', 'when'], 'thou')\n",
      "(['when', 'thou'], 'art')\n",
      "(['thou', 'art'], 'old,')\n",
      "(['art', 'old,'], 'And')\n",
      "(['old,', 'And'], 'see')\n",
      "(['And', 'see'], 'thy')\n",
      "(['see', 'thy'], 'blood')\n",
      "(['thy', 'blood'], 'warm')\n",
      "(['blood', 'warm'], 'when')\n",
      "(['warm', 'when'], 'thou')\n",
      "(['when', 'thou'], \"feel'st\")\n",
      "(['thou', \"feel'st\"], 'it')\n",
      "([\"feel'st\", 'it'], 'cold.')\n"
     ]
    }
   ],
   "source": [
    "# Creates the trigram\n",
    "trigrams = [([test_sentence[i], \n",
    "            test_sentence[i + 1]], \n",
    "            test_sentence[i + 2]) for i in range(len(test_sentence) - 2)]\n",
    "for trigram in trigrams:\n",
    "    print(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_index = {word : i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view(1, -1)\n",
    "        \n",
    "        z1 = self.linear1(embeds)\n",
    "        a1 = F.relu(z1)\n",
    "        \n",
    "        z2 = self.linear2(a1)\n",
    "        a2 = F.log_softmax(z2, dim=1)\n",
    "        \n",
    "        return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loss Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[518.5732445716858, 516.1532635688782, 513.7477684020996, 511.3560872077942, 508.9777936935425, 506.61112451553345, 504.2554540634155, 501.91208124160767, 499.5782382488251, 497.25394582748413, 494.9389293193817, 492.63220477104187, 490.331910610199, 488.03724455833435, 485.74853467941284, 483.46796464920044, 481.1920232772827, 478.91941952705383, 476.6516783237457, 474.38761734962463]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for context, target in trigrams:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Prepares data.\n",
    "        context_indices = torch.tensor([word_to_index[w] for w in context], \n",
    "                                       dtype=torch.long)\n",
    "        \n",
    "        # Forward prop.\n",
    "        log_probs = model(context_indices)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_index[target]], \n",
    "                                                     dtype=torch.long))\n",
    "        \n",
    "        # Backward prop.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updates the params.\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "\n",
    "print(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
