\# synthetic error-corrected data  
\# automatic post-editing model  
\# iterative decoding  
\# model ensembling  
\# edit-weighted MLE objective  
\# right-to-left re-ranking  
\# external spell checker  
\# official scripts
\# Adam linear warm-up


[benchmark](https://www.zhihu.com/question/317672811)  
noisy channel model: [1](https://www.cnblogs.com/hapjin/p/8012069.html), [2](https://blog.csdn.net/kunpen8944/article/details/83066460)  
[$F_{0.5}$](https://blog.csdn.net/qq_14997473/article/details/82684300)  
[Moses: a tool for machine translation](http://www.statmt.org/moses/)
[MGIZA++: a tool for word aligning](http://www.52nlp.cn/the-issue-of-parallel-in-moses-model-training#more-809)  
KenLM: a tool for training language models
MERT: an optim method  
BLEU: [1](https://www.cnblogs.com/jiangxinyang/p/10523585.html), [2](https://www.cnblogs.com/by-dream/p/7679284.html), [3](https://blog.csdn.net/CharlesOyfz/article/details/90668423)  
byte-pair encoding: [1](https://blog.csdn.net/jmh1996/article/details/89286898), [2](https://blog.csdn.net/foneone/article/details/103811328)  

\# word-aligning
\# corruption-base data synthesis approach
\# unsupervised SMT
